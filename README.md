# üá≤üá≥ Fine-tuned Mongolian LLM (Llama-2-7B + LoRA + Unsloth)

**Llama-2-7B —Å—É—É—Ä—å –∑–∞–≥–≤–∞—Ä—ã–≥ –º–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä instruction –¥–∞–≥–∞—Ö, –∞—Å—É—É–ª—Ç-—Ö–∞—Ä–∏—É–ª—Ç –∑—ç—Ä—ç–≥ NLP –¥–∞–∞–ª–≥–∞–≤–∞—Ä—Ç –∑–æ—Ä–∏—É–ª–∂ Parameter-efficient (PEFT) –∞—Ä–≥–∞–∞—Ä LoRA –±–æ–ª–æ–Ω Unsloth –∞—à–∏–≥–ª–∞–Ω fine-tune —Ö–∏–π—Å—ç–Ω.**

---

## ‚ú® –û–Ω—Ü–ª–æ–≥

- **–°—É—É—Ä—å –∑–∞–≥–≤–∞—Ä:** Llama-2-7B (Meta AI)
- **–°—É—Ä–≥–∞–ª—Ç—ã–Ω –∞—Ä–≥–∞:** LoRA + 4-bit Quantization
- **Framework:** Unsloth (Colab optimized)
- **Dataset —Ñ–æ—Ä–º–∞—Ç:** Alpaca (`instruction`, `input`, `output`)
- **–ó–æ—Ä–∏–ª–≥–æ:** –ú–æ–Ω–≥–æ–ª —Ö—ç–ª–Ω–∏–π LLM-–Ω –∑–∞–∞–≤–∞—Ä –¥–∞–≥–∞—Ö –±–æ–ª–æ–Ω QA —á–∞–Ω–∞—Ä—ã–≥ —Å–∞–π–∂—Ä—É—É–ª–∞—Ö

---

## ‚öôÔ∏è –ó–∞–≥–≤–∞—Ä—ã–Ω —Ç–æ—Ö–∏—Ä–≥–æ–æ

```python
model_name = "meta-llama/Llama-2-7b-hf"
max_seq_length = 2048
lora_config = {
  "r": 16,
  "alpha": 16,
  "target_modules": [
    "q_proj", "k_proj", "v_proj", "o_proj",
    "gate_proj", "up_proj", "down_proj"
  ],
  "load_in_4bit": True
}
```

---

## –°—É—Ä–≥–∞–ª—Ç—ã–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä“Ø“Ø–¥

```python
training_args = {
  "per_device_train_batch_size": 2,
  "gradient_accumulation_steps": 4,
  "warmup_steps": 5,
  "num_train_epochs": 6,
  "learning_rate": 2e-4,
  "optimizer": "adamw_8bit",
  "weight_decay": 0.01,
  "lr_scheduler_type": "linear",
  "save_steps": 100,
  "save_total_limit": 3
}
```

## Dataset –∂–∏—à—ç—ç

```json
{
  "instruction": "–•–∏–π–º—ç–ª –æ—é—É–Ω —É—Ö–∞–∞–Ω –≥—ç–∂ —é—É –≤—ç?",
  "input": null,
  "output": "–•–∏–π–º—ç–ª –æ—é—É–Ω —É—Ö–∞–∞–Ω –±–æ–ª –∫–æ–º–ø—å—é—Ç–µ—Ä–∏–π–Ω —à–∏–Ω–∂–ª—ç—Ö —É—Ö–∞–∞–Ω—ã —Å–∞–ª–±–∞—Ä –±”©–≥”©”©–¥ ”©–≥”©–≥–¥–ª”©”©—Å —Å—É—Ä–∞–ª—Ü–∞–∂, –ª–æ–≥–∏–∫ —à–∏–π–¥–≤—ç—Ä –≥–∞—Ä–≥–∞—Ö —á–∞–¥–≤–∞—Ä—Ç–∞–π —É—Ö–∞–∞–ª–∞–≥ —Å–∏—Å—Ç–µ–º —é–º."
}
```

---

## ”®–≥”©–≥–¥–ª–∏–π–Ω —Å–∞–Ω–≥–∏–π–Ω —á–∞–Ω–∞—Ä—ã–Ω —Ç–æ–º –∞—Å—É—É–¥–∞–ª

| –ê—Å—É—É–¥–∞–ª | –¢–∞–π–ª–±–∞—Ä |
|---|---|
| `input` = float64 | –¢–µ–∫—Å—Ç –±–∞–π—Ö —ë—Å—Ç–æ–π —Ç–∞–ª–±–∞—Ä—Ç —Å–∞–Ω–∞–º—Å–∞—Ä–≥“Ø–π **—Ç–æ–æ** –æ—Ä—Å–æ–Ω |
| –ê–≤—Ç–æ –æ—Ä—á—É—É–ª–≥–∞ | –ê–Ω–≥–ª–∏‚Üí–ú–æ–Ω–≥–æ–ª –æ—Ä—á—É—É–ª–≥–∞ **–¥“Ø—Ä–º–∏–π–Ω –±–æ–ª–æ–Ω —É—Ç–≥—ã–Ω –∏—Ö –∞–ª–¥–∞–∞—Ç–∞–π** |
| Wrong facts | –¢“Ø“Ø—Ö, –≥–∞–∑–∞—Ä–∑“Ø–π, —à–∏–Ω–∂–ª—ç—Ö —É—Ö–∞–∞–Ω—ã **–±–∞—Ä–∏–º—Ç —Ö—É–¥–∞–ª/–∑”©—Ä—á–∏–ª—Ç—ç–π** |
| Mixed languages | –î–∞—Ç–∞–¥ **–º–æ–Ω–≥–æ–ª, –∞–Ω–≥–ª–∏, —Ö—è—Ç–∞–¥** —Ö–æ–ª–∏–≥–¥—Å–æ–Ω |
| Hallucination –∏—Ö | –•–∞—Ä–∏—É–ª—Ç—É—É–¥ –ª–æ–≥–∏–∫ –±–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç **—Ç–∞—Å–∞—Ä—Å–∞–Ω, —Ö–∏–π “Ø–∑—ç–≥–¥—ç–ª—Ç—ç–π** |

### –ù”©–ª”©”©:
```
   –°—É—É—Ä—å Llama-2-—ã–Ω –º—ç–¥–ª—ç–≥ –º—É—É –¥–∞—Ç–∞–¥ —Ö—ç—Ç overfit —Ö–∏–π—Å–Ω—ç—ç—Å  
   ‚ÄúCatastrophic Forgetting + Bad Overfitting‚Äù “Ø“Ø—Å—ç–∂, –±—É—Ä—É—É —Ö–∞—Ä–∏—É–ª—Ç ”©–≥–¥”©–≥ –±–æ–ª—Å–æ–Ω.
```
